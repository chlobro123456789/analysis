---
title: "looming"
author: "Chloe Brown"
date: "04/10/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

I have three sets of data here. The first is looming which compares an expanding black circle on white background with an expanding white circle on grey background. The second compares an expanding black circle on white background (positive control) with two stimuli with an even intensity as the two circles expand. The third set of data compiles both experiments into one. The two experiments were done several months apart.


```{r}
library(sciplot)
library(multcomp)
library(ade4)
library(vegan)
library(ggplot2)
library('tidyverse')
library(lme4)
library('AICcmodavg')
```

```{r}
loomingcomb <- read_csv("looming_comb.csv")
loomingcomb %>% filter(experiment=="first") %>% droplevels -> looming
loomingcomb %>% filter(experiment=="even") %>% droplevels -> loomingeven
```

The way above has 600 rows for looming even instead of 630 in that csv. 


```{r}

looming$stimulus <- as.factor(looming$stimulus)
looming$chiton <- as.factor(looming$chiton)
looming$experiment <-as.factor(looming$experiment)
looming$response <- as.numeric(looming$response)


str(looming)
```

```{r}
#barplot
mean.countlooming <- tapply(looming$response, list(looming$stimulus), mean)
mean.countlooming
sd.count <- tapply(looming$response, list(looming$stimulus), sd)
sd.count
n.count <- tapply(looming$response, list(looming$stimulus), length)
n.count
se.count <- sd.count/sqrt(n.count)
se.count
mids <- barplot(mean.countlooming, ylim = c(0,1), xlab = "Stimulus", ylab = "Shadow Responses Elicited (%)") 
mids <- barplot(mean.countlooming, ylim = c(0,1), xlab = "Stimulus", ylab = "Shadow Responses Elicited (%)") +arrows(mids, mean.countlooming-se.count, mids, mean.countlooming+se.count,code = 3, angle = 90, length = 0.1)

```


```{r}
#for second experiment with even intensity stimuli and black circle
loomingeven$stimulus <- as.factor(loomingeven$stimulus)
loomingeven$chiton <- as.factor(loomingeven$chiton)
loomingeven$experiment <- as.factor(loomingeven$experiment)
loomingeven$response <-as.numeric(loomingeven$response)

str(loomingeven)
```
Even black is a black circle on white background that expands to a lighter one on a white background.
Even background is a white circle on a grey background expanding to a grey circle on a white background.

```{r}
#barplot
mean.counte <- tapply(loomingeven$response, list(loomingeven$stimulus), mean)
mean.counte
sd.counte <- tapply(loomingeven$response, list(loomingeven$stimulus), sd)
sd.counte
n.counte <- tapply(loomingeven$response, list(loomingeven$stimulus), length)
n.counte
se.counte <- sd.counte/sqrt(n.counte)
se.counte
midz <- barplot(mean.counte, ylim = c(0,1), xlab = "Stimulus", ylab = "Shadow Responses Elicited (%)") 
midz <- barplot(mean.counte, ylim = c(0,1), xlab = "Stimulus", ylab = "Shadow Responses Elicited (%)") +arrows(midz, mean.counte-se.counte, midz, mean.counte+se.counte,code = 3, angle = 90, length = 0.1)

```

#Models for just looming even

##Null model
```{r}

##### a null model

evenmodel.null <-glmer(response ~ 1 + (1|chiton), data = loomingeven, family = binomial(),                             control = glmerControl(optimizer = "optimx", calc.derivs = FALSE,
                                              optCtrl = list(method = "nlminb", starttests = FALSE)))  #  

```

##to see if there's an effect of length
```{r}
loomingmodel.example <- glmer(response ~ stimulus * length + (1|chiton),
                              data = loomingeven, family = binomial("logit"),      
                    control = glmerControl(
                      optimizer = "optimx", calc.derivs = FALSE,
                                           optCtrl = list(method = "nlminb", starttests = FALSE)))  

loomingmodel.example2 <- glmer(response ~ stimulus + length + (1|chiton),
                              data = loomingeven, family = binomial("logit"),      
                    control = glmerControl(
                      optimizer = "optimx", calc.derivs = FALSE,
                                           optCtrl = list(method = "nlminb", starttests = FALSE)))  

loomingmodel.example3 <- glmer(response ~ stimulus + (1|chiton),
                              data = loomingeven, family = binomial("logit"),      
                    control = glmerControl(
                      optimizer = "optimx", calc.derivs = FALSE,
                                           optCtrl = list(method = "nlminb", starttests = FALSE)))  

anova(loomingmodel.example,loomingmodel.example2,loomingmodel.example3,evenmodel.null)
summary(loomingmodel.example3)
```
AIC comparison shows that the model that includes an interaction between length and stimulus. Thus length will be considered.

## Just Stimulus Model

```{r}
evenmodel <-glmer(response ~ stimulus + (1|chiton), data = loomingeven, family = binomial(),      
                  control = glmerControl(optimizer = "optimx", calc.derivs = FALSE,
                                         optCtrl = list(method = "nlminb", starttests = FALSE)))  
summary(evenmodel)
```

The model was affected by individuals so added different into evenmodel.slope



##adding diff slope for chitons.
```{r}
evenmodel.slope <-glmer(response ~ stimulus + (1+stimulus|chiton), data = loomingeven, family = binomial(), control = glmerControl(optimizer = "optimx", calc.derivs = FALSE,
                                         optCtrl = list(method = "nlminb", starttests = FALSE)))
summary(evenmodel.slope)
```


#adding diff slope for chitons and interaction with length
```{r}
evenmodel.slope2 <-glmer(response ~ stimulus*length + (1+stimulus|chiton), data = loomingeven, family = binomial(), control = glmerControl(optimizer = "optimx", calc.derivs = FALSE,
                                         optCtrl = list(method = "nlminb", starttests = FALSE)))
summary(evenmodel.slope)
```


```{r}
anova(evenmodel.slope2,evenmodel.slope,loomingmodel.example)
summary(loomingmodel.example)
summary(glht(loomingmodel.example, mcp(stimulus="Tukey")))
```
The best model is the one that includes an interaction between stimulus and length, but considering different response rates for each chiton does not make a difference. Thus loomingmodel.example is the best model.


I think from this I can conclude that the biggest effect of individual is on the positive control ("black"), but also has an impact on even background,compared with even black. Length slightly affects the responses of even black, but not much impact on +ive control or even background. 


#Combination of looming even and looming

```{r}
loomingcomb$stimulus <- as.factor(loomingcomb$stimulus)
loomingcomb$chiton <- as.factor(loomingcomb$chiton)
loomingcomb$experiment <-as.factor(loomingcomb$experiment)
loomingcomb$response <-as.numeric(loomingcomb$response)

str(loomingcomb)
```



```{r}
bargraph.CI(stimulus, response, group = experiment, legend=T, data=loomingcomb, ylim=c(0,1), xlab = "Stimulus", ylab = "Response") #tp see black responses separately.

```

########## LME4 Analysis  ###########
```{r}
loomingmodel.0 <-glmer(response ~ 1  + (1|chiton), data = loomingcomb, family = binomial(), 
                       control = glmerControl(optimizer = "optimx", calc.derivs = FALSE,
                                           optCtrl = list(method = "nlminb", starttests = FALSE)))



loomingmodel.5<- glmer(response ~ stimulus + experiment + (1|chiton), data = loomingcomb, family =
                         binomial(), control = glmerControl(optimizer = "optimx", calc.derivs = FALSE,
                                           optCtrl = list(method = "nlminb", starttests = FALSE)))  



loomingmodel.3 <-glmer(response ~ experiment + (1|chiton), data = loomingcomb, family = binomial(), 
                       control = glmerControl(optimizer = "optimx", calc.derivs = FALSE,
                                              optCtrl = list(method = "nlminb", starttests = FALSE)))


loomingmodel.int <-glmer(response ~ stimulus*experiment  + (1|chiton), data = loomingcomb, family = 
                           binomial(), control = glmerControl(optimizer = "optimx", calc.derivs = FALSE,
                                             optCtrl = list(method = "nlminb", starttests = FALSE)))



loomingmodel.intslope <-glmer(response ~ stimulus*experiment  + (1+stimulus|chiton), data = loomingcomb, 
                          family = binomial(), control = glmerControl(optimizer = "optimx",
                              calc.derivs = FALSE, optCtrl = list(method = "nlminb", starttests = FALSE))) 

anova(loomingmodel.5, loomingmodel.3,loomingmodel.0, loomingmodel.intslope)
summary(glht(loomingmodel.5, mcp(stimulus="Tukey")))
```

> I'm not entirely sure that the two .int models worked because of an error, I presume it's because there's not responses for both experiments. Maybe if I explain why I tried to compare them. I wanted to see if the response rate across the black condition (the only stimulus in BOTH treatments) is the same for both experiments. So I've made all these modes because I wasn't actually sure how to do it.


> Also from the Tukey's of loomingmodel.5 (AIC declared the best), There's a significant difference between all treatments, apart form the white circle and even background. I'm not sure if there's a problem with the black condition because it's not yet determined whether the two experiments had an effect on the responses to a plain black expanding circle.


```{r}
ex_fixef <- fixef(loomingmodel.example)
print(paste0(round(pnorm(ex_fixef[1])*100,2),"%"))
```

Whereas, this control (Even background) is half of the time 



```{r}
ex_fixef <- fixef(evenmodel.slope)
ex_fixef
print(paste0(round(pnorm(ex_fixef[1]+ex_fixef[2])*100,2),"%"))
```

And the other most of the time

```{r}
ex_fixef <- fixef(evenmodel.slope)
print(paste0(round(pnorm(ex_fixef[1]+ex_fixef[3])*100,2),"%"))
```
99.99, 47.89, 86.12 - with bestmodel from loomingcomb (loomingmodel.5)
99.91,82.03, 28.03 - with best model from looming even (loomingmodel.example)
99.91,47.39,85.86 - with the second best model (evenmodel.slope) from looming even without an interaction with length.
black, evenbackground, evenblack.
From these averages, it seems that the best model isnt the one from the analysis of just looming_even that includes an interaction between length and stimulus because these means are not anywhere near those averaged further up: 
   Black     even_background     even_black 
   0.965           0.490           0.710 

```{r}
mloomingmodel.example <- c(99.91,82.03, 28.03) 
mevenmodel.slope <- c(99.91,47.39,85.86)
mloomingmodel.5 <- c(99.99, 47.89, 86.12)
xaxis <-c('black', 'evenbackground', 'evenblack')
ggplot() + geom_point(aes(x = xaxis, y=mloomingmodel.example), colour = "red", pch = 1, size = 5) + geom_point(aes(x = xaxis, y=mevenmodel.slope), colour = "black", pch = 2, size = 5) + geom_point(aes(x = xaxis, y=mloomingmodel.5), colour = "green", pch = 3, size = 5)
```


### Models


```{r}
loomingmodel.example4 <- glmer(
  response ~ stimulus + (1|chiton),
  data = loomingcomb, family = binomial("logit"),      
  control = glmerControl(
  optimizer = "optimx", calc.derivs = FALSE,
  optCtrl = list(method = "nlminb", starttests = FALSE)))  

summary(loomingmodel.example4)
```

This gives you both a positive and a negative control. Can I still do this even though the individuals are separate for each treatment?

```{r}
ex_fixef <- fixef(loomingmodel.example4)
print(paste0(round(pnorm(ex_fixef[1])*100,2),"%"))
```

Whereas, this control (Even background) is half of the time 


```{r}
ex_fixef <- fixef(evenmodel.slope)
ex_fixef
print(paste0(round(pnorm(ex_fixef[1]+ex_fixef[2])*100,2),"%"))
```

And the other most of the time

```{r}
ex_fixef <- fixef(evenmodel.slope)
print(paste0(round(pnorm(ex_fixef[1]+ex_fixef[3])*100,2),"%"))
```
99.99, 47.89, 86.12 - with bestmodel from loomingcomb (loom.m.5)
99.91,82.03, 28.03 - with best model from looming even (loom.m.example)
99.91,47.39,85.86 - with the second best model (evenmodel.slope) from looming even without an interaction with length.
black, evenbackground, evenblack.
From these averages, it seems that the best model isnt the one from the analysis of just looming_even that includes an interaction between length and stimulus because these means are not anywhere near those averaged further up: 
   Black     even_background     even_black 
   0.965           0.490           0.710 

```{r}
mloom.m.example <- c(99.91,82.03, 28.03) 
mevenmodel.slope <- c(99.91,47.39,85.86)
mloom.m.5 <- c(99.99, 47.89, 86.12)
xaxis <-c('black', 'evenbackground', 'evenblack')
ggplot() + geom_point(aes(x = xaxis, y=mloom.m.example), colour = "red", pch = 1, size = 5) + geom_point(aes(x = xaxis, y=mevenmodel.slope), colour = "black", pch = 2, size = 5) + geom_point(aes(x = xaxis, y=mloom.m.5), colour = "green", pch = 3, size = 5)
```


### Models


```{r}
loom.m.example4 <- glmer(
  response ~ stimulus + (1|chiton),
  data = loomingcomb, family = binomial("logit"),      
  control = glmerControl(
  optimizer = "optimx", calc.derivs = FALSE,
  optCtrl = list(method = "nlminb", starttests = FALSE)))  

summary(loom.m.example4)
```

This gives you both a positive and a negative control. Can I still do this even though the individuals are separate for each treatment?

```{r}
library(ggeffects)
ggpredict(loomingmodel.5,'stimulus') %>% plot()
```

### Notes

I don't think it makes sense to include both *stimulus* and *experiment* in the full models as separate fixed effects. 

For instance, in the model **response ~ stimulus*experiment + (1|chiton)** this is asking: is the response conditioned upon the stimulus type and/or whether it was the first (control) set of experiments or the second (even) set of experiments or upon the interaction of these things (as well as the chiton individuals). But with one exception the different stimuli are not shared between the sets of experiments and cannot be compared (neither can the individuals) - this is why lme4 complains and says they are *rank deficient*. 

It's also unclear to me what is the scientific import of being part of the first experiment or the second - surely only the stimuli used are important. I would do one of two things:

*1. Wrap the experiments together by using the stimulus but not experiment as a fixed effect. The random effect of individual already accounts for the fact that individuals vary. If you wanted you could also add experiment as a random effect given the sets of experiments were at different times, though I do not think that this is essential.

*2. Treat the two sets of experiments as separate and analyse them with different models. 

I have modified the above models in the manner of (1) in the chunk below:


```{r}
loom.m.empty <-glmer(response ~ 1 + (1|chiton),
                       data = loomingcomb,
                       family = binomial(), 
                       control = glmerControl(optimizer = "optimx", 
                                              calc.derivs = FALSE,
                                           optCtrl = list(method = "nlminb", 
                                                          starttests = FALSE)))


loom.m.stimulus <- glmer(response ~ stimulus + (1|chiton), 
                       data = loomingcomb, 
                       family =        binomial(), 
                       control = glmerControl(optimizer = "optimx", calc.derivs = FALSE,
                                           optCtrl = list(method = "nlminb", 
                                                          starttests = FALSE)))  

loom.m.full <-glmer(
  response ~ stimulus + (1+stimulus|chiton),
                              data = loomingcomb, 
                          family = binomial(),
                          control = glmerControl(optimizer = "optimx",
                              calc.derivs = FALSE,
                              optCtrl = list(method = "nlminb", starttests = FALSE))) 

anova(loom.m.empty, loom.m.stimulus,loom.m.full)
```


### Post-hoc Tukey test

```{r}
summary(glht(loom.m.stimulus, mcp(stimulus="Tukey")))
```

### Plot the marginal effects

```{r}
library(ggeffects)
ggpredict(loom.m.stimulus,'stimulus') %>% plot()
```


