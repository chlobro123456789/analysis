---
title: "Threshold girdle"
author: "Chloe Brown & John Kirwan"
date: '2020-10-01'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library('sciplot')
library('multcomp')
library('ade4')
library('vegan')
library('ggplot2')
library('lme4')
library('tidyverse')
library('ggeffects')
library('AICcmodavg') # Used for AIC comparison
library('optimx')
```


```{r}
thresholdcomp              <- read_csv("thresholdcomp.csv")
thresholdcomp$treatment    <- as.factor(thresholdcomp$treatment)
thresholdcomp$size         <- as.factor(thresholdcomp$size)
thresholdcomp$individual   <- as.factor(thresholdcomp$individual)
thresholdcomp$response     <- as.factor(thresholdcomp$response)
str(thresholdcomp)
```

# Identifying any crazy individuals
```{r}

thresholdcomp%>% group_by(individual) %>%
  filter(stimulus=="-0.97") %>% #min(thresholdcomp$stimulus) - this gets the most negative stimulus (+ive control)
  summarise(resp = sum(as.numeric(response)-1)/length(as.numeric(response)) ) %>%
  arrange(resp) %>% head(80)

```

24 would appear to be the single worst animal - having responded a quarter of the time with the clearest stimulus. I think you could justifiably exclude those animals which did not respond robustly to your positive control (e.g. those which responded less than 75% of the time). 

I've excluded the individuals with less than 75% response rate in the .csv file.

# Graphs

```{r}
thresholdcomp %>% 
  ggplot(aes(x = factor(stimulus),fill = response)) + 
    geom_bar(position = "fill")
```

### Likelihood models with lme4 excluding the positive control (-0.97)

If it says singular thing then it means there is not enough infomration because you have split the data up too much with effects. If model not working, try changing optimisation. The optimiser that works well is the 'optimx'


#excluding positive control from data set

```{r}
nowhole<- filter(thresholdcomp, stimulus>-0.97)
nowhole$treatment    <- as.factor(nowhole$treatment)
nowhole$size         <- as.factor(nowhole$size)
nowhole$individual   <- as.factor(nowhole$individual)
nowhole$response     <- as.factor(nowhole$response)
str(nowhole)
```
#Models

##Null Model
```{r}
compmodel.null <- glmer(
  response ~ 1  + (1|individual) + (1|stim_order),
  data = nowhole, family = binomial("logit"),
  control = glmerControl(optimizer = "optimx", calc.derivs = FALSE,
                         optCtrl = list(method = "nlminb", starttests = FALSE)))
```


# to see if there's an effect of size.
```{r}
#### to see if theres an effect of size

compmodel.length <- glmer(
  response ~ length  + (1|individual) + (1|stim_order),
  data = nowhole, family = binomial("logit"),
  control = glmerControl(optimizer = "optimx", calc.derivs = FALSE,
                         optCtrl = list(method = "nlminb", starttests = FALSE)))
summary(compmodel.length)
anova(compmodel.null,compmodel.length)
```
There's no SD between the null model and length, thus length is excluded from main model.


#### Main model

```{r Main model}
compmodel<- glmer(
  response ~ stimulus + treatment + (1|individual) + (1|stim_order),
  data = nowhole, family = binomial("logit"),
  control = glmerControl(optimizer = "optimx", calc.derivs = FALSE,
                         optCtrl = list(method = "nlminb", starttests = FALSE))) 

summary(compmodel)
```
Stimulus and treatmen have an effect.

## Model without stimulus and only treatment 
(Whole, Valve, Girdle)

```{r Null model}
compmodel.treat <-glmer(
  response ~ treatment + (1|individual) + (1|stim_order),
  data = nowhole, family = binomial(), 
  control = glmerControl(optimizer = "optimx", calc.derivs = FALSE,
            optCtrl = list(method = "nlminb", starttests = FALSE)))

summary(compmodel.treat)
```

#### Full model with stimulus, treatment, and their interaction

```{r}
compmodel.int <-glmer(
  response ~ stimulus*treatment  + (1|individual) + (1|stim_order),
  data = nowhole, family = binomial(),
  control = glmerControl(optimizer = "optimx", calc.derivs = FALSE,
             optCtrl = list(method = "nlminb", starttests = FALSE)))

summary(compmodel.int)
```

        
#### Full random slope model with stimulus, treatment, and their interaction and random slopes
                                             
```{r}
compmodel.intslope <-glmer(
  response ~ stimulus*treatment  + (1+stimulus|individual) + (1+stimulus|stim_order),
  data = nowhole, family = binomial(),
  control = glmerControl(optimizer = "optimx", calc.derivs = FALSE,
                optCtrl = list(method = "nlminb", starttests = FALSE))) 

summary(compmodel.intslope)
```

                                             
                                             
#putting (1+stimulus|random) effect tells the model that there may be differing intercepts based on the random effect, i.e. the baseline responses of the individual and those of differing sizes may be different. I didn't add to stim_order because it threw an error.
# from New Statistics for the Design Scientist - 'Slope random effects represent, how much individuals differ in their change of response, when conditions change. Consider case BrowsingAB, where the population averages of the designs were not that far apart. That can mean they are truly not that different. But it can also mean that some users do a lot better with A, and others with B. Which design is preferred could largely depend on the person.' The	 notation	 “(1+attitude|subject)”	means	 that	 you	 tell	
'the	 model	 to	 expect	 differing	 baseline-levels	 of	 frequency	 (the	 intercept,	
represented	 by	1)	as	well	as	differing	 responses	 to	 the	main	 factor	in	 question,	
which	is	“attitude”	in	this	case.' - from https://arxiv.org/ftp/arxiv/papers/1308/1308.5499.pdf


```{r}
anova(compmodel,compmodel.null,compmodel.treat,compmodel.int, compmodel.intslope) 
```
The model with the lowest AIC (thus the best of the ones tested) is compmodel.intslope.

#### Look at the model summary of the best fit

```{r}
summary(compmodel.intslope)
```

### Chloe's comments
> What I think I can say: there's an effect of treatment because there the best model included an interaction between the stimuli the individual has a strong (I think) effect and length does but less so.

Yes. It is the best model, it also has far more degrees of freedom than the others but it is much better regardless, as revealed by the AIC values and the LRT tests.

Yes, the effect of individual is large, in relation to how the response changed with stimulus (it makes sense that it should be conditional upon stimulus - they should all do equally poorly when there is no stimulus). Did you observe this? Did different animals perform very differently? You can also make a summary plot of the original data, which plots a different line for each individual to test this. 

Yes, the effect is length is much smaller. If you wanted, you could also filter your data to include only large, salient stimuli and plot the proportion responses against body length.

> I'm not sure how to interpret the intercept and stimulus part.

The intercept and slope (stimulus) are the parameters of the regression line but they are still in logit space. You can get the model fit by plugging them back into the line formula (y=mx+c) and putting it into logit space with the logit link, which in R, you can apply with pnorm().

> I don't know what's going on with the correlation of fixed effects or the fixed effects.

Don't worry so much about the correlations. That is literally telling you if they are correlated (it's a covariance matrix) which can be important, for instance if you have highly correlated effects effects which can be problematic. 

The values out of the fix effects are *contrasts* contrasted against the default situation, which is the intercept (decided by the order of your factor levels). To get other values, you add the effects; e.g. to get the response in relation to stimulus with the valve stimulus, you can get. Again, you can compare to the panel above.


```{r}
fixed <- fixef(compmodel.int) 
fixed # pull out the fixed effect coefficients.


X  <- seq(from=-1,to=0.2,by=.02)
y_control <- pnorm( fixed[2]*X + fixed[1])
y_valve <- pnorm( (fixed[2] + fixed[6])*X + (fixed[1] + fixed[4]) )
y_girdle <- pnorm( (fixed[2] + fixed[5])*X + (fixed[1] + fixed[3]) )
plot(X,y_control,main='Response to stimuli',col="blue",xlim=c(-1,0.2)) + lines(X,y_control,col="blue") + points(X,y_valve,col="orange") + lines(X,y_valve,col="orange") + points(X,y_girdle,col="black") + lines(X,y_girdle,col="black") #+abline(v=0,col="grey")

```

You can compare how to predictions out of the model (below), though I think this should be across all treatments. 


```{r}
x_prediction_sequence <- seq(from=-1, to=0.2, by= 0.005)

predz <- ggpredict(
  compmodel.int, 
  terms = c('stimulus [x_prediction_sequence]','treatment'),
  type='fixed', # can also be random
  ci.lvl = 0.95, # 1- alpha (usually 0.05) level of confidence intervals
                   ) 
predz %>% plot(colors=c("blue","black","orange"))
```




# Building the graph with predz and means of each

```{r}
controlpredz <- subset(predz, group == "Control")
girdlepredz <- subset(predz, group == "Girdle")
valvepredz <- subset(predz, group == "Valve")
```
New data frames for each treatment.



##Parameters for graph
```{r}
xgirdle <- girdlepredz$x
ygirdle <- girdlepredz$predicted
girdlemin <- girdlepredz$conf.low
girdlemax <- girdlepredz$conf.high
xmgirdle <- c(-0.97,-0.96,-0.9,-0.73,-0.52,-0.26,-0.03,0) # stimulus treatments. Girdle has an extra one -0.73 compared to the others.
ymgirdle <- c(0.95986622, 0.81012658, 0.77021277, 0.66530612, 0.52343750, 0.17241379, 0.02348993, 0.01672241) #mean response rates

xvalve <-valvepredz$x
yvalve <- valvepredz$predicted
valvemin <- valvepredz$conf.low
valvemax <- valvepredz$conf.high
xmvalve <- c(-0.97,-0.96, -0.9,-0.52, -0.26, -0.03, 0)
ymvalve <- c(0.97765363,0.91304348,0.88554217,0.86206897, 0.75428571, 0.10169492, 0.05555556)

xwhole <- controlpredz$x
ywhole <- controlpredz$predicted
wholemin <- controlpredz$conf.low
wholemax <- controlpredz$conf.high
xmwhole <-c(-0.97, -0.96, -0.9, -0.52, -0.26, -0.03, 0) 
ymwhole <- c(0.96111111, 0.98333333, 0.97777778, 0.95555556, 0.96111111, 0.36111111, 0.03333333)
Treatment <- c("Control" = "blue", "Valve" = "orange", "Girdle" = "black")
```




##Finding the intercept for each condition
```{r}
#control
derivative_control = c(diff(controlpredz$predicted) / diff(controlpredz$x), 0)
find.df.control <- cbind.data.frame(controlpredz$x,derivative_control)
ggplot(find.df.control, aes(controlpredz$x, derivative_control)) + geom_line()
max_deriv_control <- which(derivative_control==min(derivative_control))
inflection_pt_control <- controlpredz$x[max_deriv_control]
inflection_pt_control

#girdle
derivative_girdle = c(diff(girdlepredz$predicted) / diff(girdlepredz$x), 0)
find.df.girdle <- cbind.data.frame(girdlepredz$x,derivative_girdle)
ggplot(find.df.girdle, aes(girdlepredz$x, derivative_girdle)) + geom_line()
max_deriv_girdle <- which(derivative_girdle==min(derivative_girdle))
inflection_pt_girdle <- girdlepredz$x[max_deriv_girdle]
inflection_pt_girdle

#valve
derivative_valve = c(diff(valvepredz$predicted) / diff(valvepredz$x), 0)
find.df.valve <- cbind.data.frame(valvepredz$x,derivative_valve)
ggplot(find.df.valve, aes(valvepredz$x, derivative_valve)) + geom_line()
max_deriv_valve <- which(derivative_valve==min(derivative_valve))
inflection_pt_valve <- valvepredz$x[max_deriv_valve]
inflection_pt_valve
```

##Graph itself
```{r}
overallplot<- ggplot() + 
  geom_line(data = girdlepredz, aes(xgirdle,ygirdle,color = "Girdle"), size = 1) + 
  geom_ribbon(aes(x = xgirdle, y=ygirdle,ymin=girdlemin, ymax=girdlemax),
              linetype=2, alpha=0.1, fill = "Black") +
  geom_point(aes(x = xmgirdle, y = ymgirdle), colour = "Black", size = 3, pch=0) +
  geom_vline(aes(xintercept = inflection_pt_girdle), colour = "Black") +
  geom_line(data = valvepredz, aes(xvalve,yvalve, color = "Valve"), size = 1) +
  geom_point(aes(x = xmvalve, y = ymvalve), colour = "orange", size = 3, pch=1) +
  geom_ribbon(aes(x = xvalve, y=yvalve,ymin=valvemin, ymax=valvemax),
              linetype=2, alpha=0.1, fill = "orange") +
  geom_vline(aes(xintercept = inflection_pt_valve), colour = "orange") +
  geom_line(data = controlpredz, aes(xwhole,ywhole,color = "Control"), size = 1) +
  geom_point(aes(x = xmwhole, y = ymwhole), colour = "blue", size = 3, pch=2) +
  geom_ribbon(aes(x = xwhole, y=ywhole,ymin=wholemin, ymax=wholemax),
              linetype=2, alpha=0.1, fill = "blue") +
  geom_vline(aes(xintercept = inflection_pt_control), colour = "blue") +
  theme_classic() + labs(x = "Weber Contrast", colours = "Legend") + 
  scale_y_continuous("Predicted Shadow Responses",
                     sec.axis = sec_axis(~ . * 100,
                                         name = "Shadow Responses Elicited (%)")) +
  scale_color_manual(values = Treatment)
overallplot 
```


To change the appearance of the raw data points - pch(diffnumberforeachpoint) so you can see all points even when v similar.




### Why the data are more extreme than the predictions?

Well done on the plot. It is not unheard of for some of the raw data points to be more extreme than the predictions. There are several reasons for this. 

* The shaded range for each is a 95% confidence interval for the fitted line. You can change the *alpha* of the confidence interval above using the ci.lvl attribute in ggpredict to anything you want, though 0.95 is conventional. Values would therefore be expected to exceed this range 95% of the time.

* The model should correspond to the data but should not recapitulate it perfectly - otherwise there would be no point running a model - you would just plot the raw data. While the raw data are in a way more *real*, the model has something the raw data lack: The likelihood function (in this case, the binomial distribution) which corresponds to how the data were made and understands what is likely and what is not.

* Specifically, this plot of the model and the set of predictions used is based only on the *fixed* effects and leaves out the *random* effects, which include the variation explained by individual differences. Having random effects in your model leads to *shrinkage* and more certain estimates by trusting less the more extreme values and more extreme individuals (or other such groups). You can also make predictions with the random effects in, which is sometimes called the prediction interval. The prediction interval will necessarily be wider because it includes this extra variation. Unfortunately, ggpredict throws an error and will not let me plot prediction intervals for this model (by setting type="random"). Commonly, we leave this out because we are not usually interested in these specific chitons but rather the population of all chitons. The raw data, however, includes this extra variation that you have taken out and will be more extreme. Ideally, you would have an extra pair of lines showing the prediction interval that would include more of the data proportions.

* I have so far talked about non-systemic fluctuations away from the fitted line in either direction - but you definitely have a systemic difference, in that the highest proportions for each treatment - corresponding to the more salient stimuli - fall below the model. This means that actually there is a lapse rate for the chitons: A rate at which the chitons fail even with a really clear stimulus.  You can estimate this rate by getting the success proportion for each treatment with the most salient stimulus (-0.95 Weber contrast) - it appears to be 0.05 in each case. (It may be lower in the case of the girdle where the most salient stimulus level conflicts slightly with the three next most salient stimulus levels - unless they have some weird preference for specific contrast levels this looks to me to be at least partly just random variation). You have too options here: You can explain that your model is slightly askew because of this lapse (and therefore the *true *threshold may be at a slightly more negative value than the fitted line) or you can introduce an upper asymptote to consider the lapse rate.  






# Make plots for individuals because this has an effect on response rate

So, since the individuals are nested within treatments rather than shared across them (a given individual is only measured for one experiment) we might check which individuals are used for each treatment and plot these. 

## Girdle animals

```{r}
set.seed(321)

girdle_ind <- unique(droplevels(
  thresholdcomp$individual[thresholdcomp$treatment=="Girdle"]))

x_prediction_sequence <- seq(from=-1, to=0.2, by= 0.005)
girdle_sample         <- as.character(sample(girdle_ind, 9))

predz <- ggpredict(
  compmodel.intslope, 
  terms = c('stimulus [x_prediction_sequence]','individual [girdle_sample]'),
  type='re', # can also be random
  ci.lvl = 0.95, # 1- alpha (usually 0.05) level of confidence intervals
                   ) 
predz %>% plot() #colors=c("blue","black","orange")
```

## Valve sample

```{r}
set.seed(161)
x_prediction_sequence <- seq(from=-1, to=0.2, by= 0.005)

valve_ind <- unique(droplevels(
  thresholdcomp$individual[thresholdcomp$treatment=="Valve"]))
valve_sample         <- as.character(sample(valve_ind, 9))

predz <- ggpredict(
  compmodel.intslope, 
  terms = c('stimulus [x_prediction_sequence]','individual [valve_sample]'),
  type='re', # can also be random
  ci.lvl = 0.95, # 1- alpha (usually 0.05) level of confidence intervals
                   ) 
            
predz %>% plot() #colors=c("blue","black","orange")
```
## Whole sample

```{r}
set.seed(254)
x_prediction_sequence <- seq(from=-1, to=0.2, by= 0.005)

whole_ind <- unique(droplevels(
  thresholdcomp$individual[thresholdcomp$treatment=="Control"]))
whole_sample <- as.character(sample(whole_ind, 9))
predz <- ggpredict(
  compmodel.intslope, 
  terms = c('stimulus [x_prediction_sequence]','individual [whole_sample]'),
  type='re', # can also be random
  ci.lvl = 0.95, # 1- alpha (usually 0.05) level of confidence intervals
                   ) 
            
predz %>% plot() #colors=c("blue","black","orange")

```

